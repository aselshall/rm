### Predicting Red Tides with LSTM + EnKF

The objective is to compare LSTM and LSTM+EnKF deep learning architectures for weekly red tide forecasting, considering various factors.

Long Short-Term Memory (LSTM) networks have shown greater efficacy in predicting red tides compared to traditional machine learning models such as linear regression, decision tree regressors, and random forest regressors. LSTMs are designed to handle sequential data, making them particularly well-suited for time series prediction tasks. They can capture the temporal dependencies and long-term patterns in data, which are crucial for accurately forecasting red tides. Traditional models like linear regression struggle with capturing such complex temporal relationships and often fall short in accuracy. Decision tree and random forest regressors, while better than linear regression in handling non-linear data, still lack the capability to effectively process sequential data. LSTMs, on the other hand, use memory cells to retain information over time, enabling them to learn and predict based on past occurrences. Additionally, LSTM networks can incorporate various input features like temperature, salinity, and nutrient levels, adjusting their weights dynamically to improve prediction accuracy. Visualization tools and techniques such as heat maps of the cell states and gates in LSTM can also provide insights into how different input features influence the prediction of red tides over time.

### **Jupyter Notebook Outline: Comparing LSTM and LSTM+EnKF for Red Tide Forecasting**

**1. Introduction and Objective**
    * Brief overview of the research problem: Predicting red tides (Karenia brevis blooms) in the Gulf of Mexico (West Florida Shelf) using machine learning.
    * State the main objective: To compare the forecasting performance of LSTM and LSTM+EnKF deep learning architectures.
    * List the specific comparisons to be made, as you outlined:
        * With and without Monte Carlo Dropout.
        * RobustScaler vs. StandardScaler for data preprocessing.
        * Basic vs. enhanced feature engineering strategies (lags, rolling aggregates - referencing `report.pdf` and `ml.ipynb` for current strategies [cite: 20, 22, 24]).
        * With and without automatic hyperparameter tuning for LSTM.
        * With and without an advanced physics-loss step for a physics-informed model.
    * Mention the goal of showing LSTM+EnKF's potential for better forecast results than standalone LSTM for publication in a peer-reviewed journal.

**2. Setup and Imports**
    * Import necessary Python libraries:
        * `pandas` for data manipulation.
        * `numpy` for numerical operations.
        * `matplotlib` and `seaborn` for plotting.
        * `scikit-learn` for preprocessing (StandardScaler, RobustScaler), model evaluation (metrics like balanced accuracy, classification report, confusion matrix [cite: 21]), and hyperparameter tuning (e.g., GridSearchCV, RandomizedSearchCV).
        * `tensorflow` and `keras` (or `pytorch`) for LSTM and LSTM+EnKF model building.
        * Libraries for EnKF implementation (if not part of the DL framework directly).
        * Libraries for SHAP or other interpretability methods (optional, but good for comparison with the Random Forest model [cite: 22]).
    * Set global configurations (e.g., random seeds for reproducibility, plot styles).

**3. Data Loading and Initial Preprocessing**
    * Load the `data_weekly_intepolated.csv` dataset.
    * Parse 'time' column as datetime objects.
    * Initial data cleaning (handle missing values if any beyond what's already interpolated).
    * Define the target variable: `kb` (Karenia brevis cell count) for regression or a derived binary/multi-class variable for bloom events (e.g., based on thresholds like >= 100,000 cells/L as in `ml.ipynb` [cite: 20]). Since the goal is weekly forecasting of "bloom events", a classification approach seems primary.
    * Shift target for 1-week-ahead prediction (as done in `ml.ipynb` [cite: 20]).

**4. Feature Engineering Strategies**
    * **4.1. Basic Feature Set:**
        * Use the original set of environmental drivers provided.
        * Minimal lag features (e.g., 1-week lag for key variables as a baseline, similar to `ml.ipynb` [cite: 20]).
    * **4.2. Enhanced Feature Set (referencing `report.pdf` and `ml.ipynb` [cite: 20, 22, 24]):**
        * Generate more extensive lag features for relevant variables (e.g., `kb`, `zos`, `salinity`, `water_temp`, `wind_speed`, `peace_discharge`, `peace_TN`, `peace_TP` for multiple previous weeks).
        * Create rolling window statistics (e.g., moving averages, min, max, standard deviation over 4 weeks or other relevant windows for variables like `peace_discharge` [cite: 20]).
        * Consider interaction terms or other derived features if ecologically relevant (e.g., wind components U and V from speed and direction).
    * Function to select feature set for different experimental runs.

**5. Data Scaling Techniques**
    * **5.1. StandardScaler:** Implement and apply.
    * **5.2. RobustScaler:** Implement and apply (noted for handling outliers, as used in `ml.ipynb` [cite: 20]).
    * Function to apply chosen scaler to training and test sets. Ensure scaler is fit *only* on training data.

**6. Model Architectures**
    * **6.1. LSTM Model:**
        * Define LSTM architecture (e.g., number of LSTM layers, units, dropout layers).
        * Placeholder for Monte Carlo Dropout implementation (can be standard dropout activated during inference).
        * Placeholder for physics-informed loss function (if applicable).
    * **6.2. LSTM + EnKF Model:**
        * Define the combined LSTM-EnKF architecture.
        * Detail how EnKF is integrated (e.g., for state updating, parameter estimation, or uncertainty quantification).
        * Placeholder for Monte Carlo Dropout.
        * Placeholder for physics-informed loss function.
    * Helper functions to build/compile models based on configuration.

**7. Experimental Design & Execution Loop**
    * Define a structured way to run and log experiments for each comparison point.
    * **Train-Test Split:**
        * Implement a time-aware split (e.g., training up to 2018, testing from 2019 onwards, as in `ml.ipynb` [cite: 20]).
    * **Loop through Model Types (LSTM, LSTM+EnKF)**
    * **Loop through Feature Sets (Basic, Enhanced)**
    * **Loop through Scaler Types (StandardScaler, RobustScaler)**
    * **Loop through Monte Carlo Dropout (With, Without)**
        * If "With", ensure dropout layers are active during prediction for uncertainty estimation.
    * **Loop through Hyperparameter Tuning (With, Without - for LSTM)**
        * If "With", use KerasTuner, Optuna, or scikit-learn's hyperparameter tuning tools with appropriate time-series cross-validation.
    * **Loop through Physics-Informed Loss (With, Without)**
        * Implement custom loss function if "With".

    * **For each combination:**
        * **7.1. Data Preparation:**
            * Select feature set.
            * Apply chosen scaler.
            * Reshape data for LSTM input (e.g., `[samples, timesteps, features]`).
        * **7.2. Model Training:**
            * Build the specified model (LSTM or LSTM+EnKF) with/without MC Dropout, with/without tuned hyperparameters.
            * Train the model using the appropriate loss function (standard or physics-informed).
            * Implement early stopping to prevent overfitting.
        * **7.3. Prediction:**
            * Generate predictions on the test set.
            * If using MC Dropout for uncertainty, perform multiple forward passes with dropout enabled.
        * **7.4. Evaluation:**
            * Calculate performance metrics:
                * Balanced Accuracy [cite: 21]
                * Precision, Recall, F1-score (especially for the "Bloom" class [cite: 21])
                * Confusion Matrix [cite: 21]
                * Area Under the Precision-Recall Curve (AUPRC)
                * Log loss/Cross-entropy
                * If regression on `kb` count is also performed: MSE, MAE.
            * If MC Dropout is used, quantify prediction uncertainty.
        * **7.5. Store Results:**
            * Log model configuration, training history, evaluation metrics, and any uncertainty measures.

**8. Results Comparison and Analysis**
    * Create tables and plots to compare the performance of all experimental runs.
    * **8.1. Primary Comparison: LSTM vs. LSTM+EnKF**
        * Compare their best-case performances across all metrics.
    * **8.2. Impact of Monte Carlo Dropout:**
        * Compare models with and without MC Dropout.
        * Analyze uncertainty estimates if applicable.
    * **8.3. Impact of Scalers:**
        * Compare RobustScaler vs. StandardScaler for each model type.
    * **8.4. Impact of Feature Engineering:**
        * Compare basic vs. enhanced feature sets.
    * **8.5. Impact of Hyperparameter Tuning (for LSTM):**
        * Show performance improvement with tuning.
    * **8.6. Impact of Physics-Informed Loss:**
        * Compare models with standard vs. physics-informed loss.
    * Visualize results (e.g., bar charts for metrics, PR curves).

**9. Interpretation (Optional but Recommended)**
    * For the best performing models (or representative ones), use techniques like SHAP (for LSTMs, DeepExplainer or GradientExplainer) or LIME to understand feature importance and model behavior. This can be compared to the Random Forest SHAP analysis[cite: 22].
    * Analyze how different input features contribute to predictions for specific bloom events.

**10. Conclusion and Future Work**
    * Summarize key findings from the comparisons.
    * Identify the best performing architecture and configuration.
    * Discuss the implications of the results for red tide forecasting (referencing the `report.pdf` [cite: 24, 25]).
    * Suggest areas for future research and model improvement (e.g., different EnKF integration strategies, more advanced feature engineering, longer forecast horizons, ensemble methods, addressing model overfitting [cite: 23]).
    * Discuss potential for operationalization as an early warning system[cite: 28].

This outline provides a comprehensive structure. We can refine it once we have more details about your LSTM+EnKF implementation. Let me know your thoughts!
